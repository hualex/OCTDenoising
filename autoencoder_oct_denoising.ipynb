{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_oct_denoising.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "YWaEX7fbmLe2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# OCT Image Denoising\n",
        "\n",
        "\n",
        "Author: Xiaolong Du"
      ]
    },
    {
      "metadata": {
        "id": "Thhq1Ex-mQ7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Autoencoder: denoising oct images\n",
        "\n",
        "Removing noise from oct images."
      ]
    },
    {
      "metadata": {
        "id": "hHUHH_2llq1I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.cuda as cuda\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Torchvision module contains various utilities, classes, models and datasets \n",
        "# used towards computer vision usecases\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0ihvnfUmfbH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create the datasets**"
      ]
    },
    {
      "metadata": {
        "id": "xeMIKlQDmjzT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n"
      ]
    },
    {
      "metadata": {
        "id": "zB9zp0d2mrgQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform=transforms.Compose([transforms.ToTensor()])\n",
        "s = time.time()\n",
        "\n",
        "#cifar10_train = datasets.CIFAR10('./data.cifar10', train=True, download=True, transform=transform)\n",
        "#cifar10_valid = datasets.CIFAR10('./data.cifar10', train=False, download=True, transform=transform)\n",
        "cifar10_train = datasets.MNIST('./dataMNIST', train=True, download=True, transform=transform)\n",
        "cifar10_valid = datasets.MNIST('./dataMNIST', train=False, download=True, transform=transform)\n",
        "e = time.time()\n",
        "print(e-s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MNZPHH0vm3rT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Utility to display the original, noisy and denoised image**"
      ]
    },
    {
      "metadata": {
        "id": "qO2EYUk5m8rN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(orig, noisy, denoised):\n",
        "    fig=plt.figure()\n",
        "    \n",
        "    #orig = orig.swapaxes(0, 1).swapaxes(1, 2)\n",
        "    #noisy = noisy.swapaxes(0, 1).swapaxes(1, 2)\n",
        "    #denoised = denoised.swapaxes(0, 1).swapaxes(1, 2)\n",
        "    orig = orig.squeeze()\n",
        "    noisy = noisy.squeeze()\n",
        "    denoised = denoised.squeeze()\n",
        "    \n",
        "    # Normalize for display purpose\n",
        "    orig     = (orig - orig.min()) / (orig.max() - orig.min())\n",
        "    noisy    = (noisy - noisy.min()) / (noisy.max() - noisy.min())\n",
        "    denoised = (denoised - denoised.min()) / (denoised.max() - denoised.min())\n",
        "    #print(orig.size())\n",
        "    \n",
        "    fig.add_subplot(1, 3, 1, title='Original')\n",
        "    plt.imshow(orig,cmap='gray')\n",
        "    \n",
        "    fig.add_subplot(1, 3, 2, title='Noisy')\n",
        "    plt.imshow(noisy,cmap = 'gray')\n",
        "    \n",
        "    fig.add_subplot(1, 3, 3, title='Denoised')\n",
        "    plt.imshow(denoised,cmap = 'gray')\n",
        "    \n",
        "    fig.subplots_adjust(wspace = 0.5)\n",
        "    plt.show()\n",
        "    \n",
        "# To test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Y8dhJCBnO-e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Some hyper parameters**"
      ]
    },
    {
      "metadata": {
        "id": "Ebtdq_GjnOR0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 250 # Reduce this if you get out-of-memory error\n",
        "learning_rate = 0.001\n",
        "noise_level = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ylhkDk7MnWD9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create the dataloader**"
      ]
    },
    {
      "metadata": {
        "id": "bAHQr98Vnsjj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cifar10_train_loader = torch.utils.data.DataLoader(cifar10_train, batch_size=batch_size, shuffle=True, num_workers=10)\n",
        "cifar10_valid_loader = torch.utils.data.DataLoader(cifar10_valid, batch_size=batch_size, shuffle=True, num_workers=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lrii66ZanvJE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The Denoising Autoencoder**"
      ]
    },
    {
      "metadata": {
        "id": "dvREjOQSnxx9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DenoisingAutoencoder(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "    \n",
        "        super(DenoisingAutoencoder, self).__init__()\n",
        "                                                            # 32 x 32 x 3 (input)\n",
        "\n",
        "        self.conv1e = nn.Conv2d(1, 24, 3, padding=2)        # 30 x 30 x 24\n",
        "        self.conv2e = nn.Conv2d(24, 48, 3, padding=2)       # 28 x 28 x 48\n",
        "        self.conv3e = nn.Conv2d(48, 96, 3, padding=2)       # 26 x 26 x 96\n",
        "        self.conv4e = nn.Conv2d(96, 128, 3, padding=2)      # 24 x 24 x 128\n",
        "        self.conv5e = nn.Conv2d(128, 256, 3, padding=2)     # 22 x 22 x 256\n",
        "        self.mp1e   = nn.MaxPool2d(2, return_indices=True)  # 11 x 11 x 256\n",
        "\n",
        "        self.mp1d = nn.MaxUnpool2d(2)\n",
        "        self.conv5d = nn.ConvTranspose2d(256, 128, 3, padding=2)\n",
        "        self.conv4d = nn.ConvTranspose2d(128, 96, 3, padding=2)\n",
        "        self.conv3d = nn.ConvTranspose2d(96, 48, 3, padding=2)\n",
        "        self.conv2d = nn.ConvTranspose2d(48, 24, 3, padding=2)\n",
        "        self.conv1d = nn.ConvTranspose2d(24, 1, 3, padding=2)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        x = self.conv1e(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2e(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3e(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4e(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv5e(x)\n",
        "        x = F.relu(x)\n",
        "        x, i = self.mp1e(x)\n",
        "        \n",
        "         # Decoder\n",
        "        x = self.mp1d(x, i)\n",
        "        x = self.conv5d(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4d(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3d(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2d(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv1d(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0reKLa5n6_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "autoencoder = DenoisingAutoencoder().cuda()\n",
        "parameters = list(autoencoder.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(parameters, lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwh0d3MUoO6K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "valid_loss = []\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    \n",
        "    # Let's train the model\n",
        "    s = time.time()\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    total_iter = 0\n",
        "    autoencoder.train()\n",
        "    for image, label in cifar10_train_loader:\n",
        "        \n",
        "        noise = torch.randn(image.shape[0], 1, 28, 28) * noise_level\n",
        "        image_n = torch.add(image, noise)\n",
        "        \n",
        "        image = Variable(image).cuda()\n",
        "        image_n = Variable(image_n).cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = autoencoder(image_n)\n",
        "        \n",
        "        loss = loss_func(output, image)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_iter += 1\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "    # Let's record the validation loss\n",
        "    \n",
        "    total_val_loss = 0.0\n",
        "    total_val_iter = 0\n",
        "    autoencoder.eval()\n",
        "    for image, label in cifar10_valid_loader:\n",
        "        \n",
        "        noise = torch.randn(image.shape[0], 1, 28, 28) * noise_level\n",
        "        image_n = torch.add(image, noise)\n",
        "        \n",
        "        image = Variable(image).cuda()\n",
        "        image_n = Variable(image_n).cuda()\n",
        "        \n",
        "        output = autoencoder(image_n)\n",
        "        loss = loss_func(output, image)\n",
        "        \n",
        "        total_val_iter += 1\n",
        "        total_val_loss += loss.item()\n",
        "        \n",
        "        \n",
        "    # Let's visualize the first image of the last batch in our validation set\n",
        "    orig = image[0].cpu()\n",
        "    noisy = image_n[0].cpu()\n",
        "    denoised = output[0].cpu()\n",
        "\n",
        "    orig = orig.data.numpy()\n",
        "    noisy = noisy.data.numpy()\n",
        "    denoised = denoised.data.numpy()\n",
        "\n",
        "    print(\"Iteration \", i+1)\n",
        "    show_img(orig, noisy, denoised)\n",
        "    \n",
        "    train_loss.append(total_loss / total_iter)\n",
        "    valid_loss.append(total_val_loss / total_val_iter)\n",
        "    e = time.time()\n",
        "    print(e-s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EarcagBAoVN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(autoencoder.state_dict(), \"./gdrive/My Drive/autoencoder.pth\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E05xNHE4orFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, label='Train loss')\n",
        "plt.plot(valid_loss, label='Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aSFEMrDVo1mH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Single image denoising"
      ]
    },
    {
      "metadata": {
        "id": "AYH3D1fFpSy_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "img, _ = random.choice(cifar10_valid)\n",
        "img    = img.resize_((1, 1, 28, 28))\n",
        "noise  = torch.randn((1, 1, 28, 28)) * noise_level\n",
        "img_n  = torch.add(img, noise)\n",
        "\n",
        "img_n = Variable(img_n).cuda()\n",
        "denoised = autoencoder(img_n)\n",
        "\n",
        "\n",
        "show_img(img[0].numpy(), img_n[0].data.cpu().numpy(), denoised[0].data.cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}